{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras import callbacks, optimizers\n",
    "from keras import backend as KB\n",
    "from keras.engine import Layer\n",
    "from keras.layers import Activation\n",
    "from keras.layers import LeakyReLU, Dense, Input, Embedding, Dropout, Reshape\n",
    "from keras.layers import Bidirectional, GRU, Flatten, SpatialDropout1D, Conv1D\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from common import vocabulary, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.6.0\n",
      "Keras version: 2.1.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "print(\"Keras version:\", K.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First attempt\n",
    "x_train: sentence - list of words  \n",
    "y_train: sentence - list of NER tag\n",
    "\n",
    "### Second attempt (maybe?)\n",
    "x_train: sentence - list of words, POS tags  \n",
    "y_train: sentence - list of NER tags\n",
    "\n",
    "### Notes\n",
    "> Does it makes sense to use 'O' as the padding for the NER tags? Should we use something else?\n",
    "> - Currently, I am using `<s>` and `</s>`  \n",
    "\n",
    "> perhaps we want to try without the I-, B- modifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"./data/conll2003/eng.train\"\n",
    "DEV_FILE = \"./data/conll2003/eng.testa\"\n",
    "TEST_FILE = \"./data/conll2003/eng.testb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\r\n",
      "\r\n",
      "EU NNP I-NP I-ORG\r\n",
      "rejects VBZ I-VP O\r\n",
      "German JJ I-NP I-MISC\r\n",
      "call NN I-NP O\r\n",
      "to TO I-VP O\r\n",
      "boycott VB I-VP O\r\n",
      "British JJ I-NP I-MISC\r\n",
      "lamb NN I-NP O\r\n"
     ]
    }
   ],
   "source": [
    "!head -10 {TRAIN_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is odd that the B-PER tag doesn't appear... investigate this.\n",
    "!grep \"B-PER\" {TRAIN_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readfile( filename, pos=False):\n",
    "    '''\n",
    "    read the conll2003 file\n",
    "    \n",
    "    filename(string) - path to conll2003 file (train, test, etc.)\n",
    "    pos(boolean) - flag if true will include pos tags in returned list\n",
    "    returns a list of lists of lists corresponding to the words in each sentence\n",
    "    \n",
    "    '''\n",
    "    f = open(filename)\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in f:\n",
    "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
    "            if len(sentence) > 0:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "            continue\n",
    "        splits = line.strip().split(' ')\n",
    "        word = [splits[0], splits[1], splits[-1]] if pos else [splits[0], splits[-1]]\n",
    "        sentence.append( word)\n",
    "\n",
    "    if len(sentence) > 0:\n",
    "        sentences.append(sentence)\n",
    "        sentence = []\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainSentences = readfile(TRAIN_FILE, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['EU', 'NNP', 'I-ORG'], ['rejects', 'VBZ', 'O'], ['German', 'JJ', 'I-MISC'], ['call', 'NN', 'O'], ['to', 'TO', 'O'], ['boycott', 'VB', 'O'], ['British', 'JJ', 'I-MISC'], ['lamb', 'NN', 'O'], ['.', '.', 'O']]\n",
      "[['Peter', 'NNP', 'I-PER'], ['Blackburn', 'NNP', 'I-PER']]\n",
      "[['BRUSSELS', 'NNP', 'I-LOC'], ['1996-08-22', 'CD', 'O']]\n",
      "[['The', 'DT', 'O'], ['European', 'NNP', 'I-ORG'], ['Commission', 'NNP', 'I-ORG'], ['said', 'VBD', 'O'], ['on', 'IN', 'O'], ['Thursday', 'NNP', 'O'], ['it', 'PRP', 'O'], ['disagreed', 'VBD', 'O'], ['with', 'IN', 'O'], ['German', 'JJ', 'I-MISC'], ['advice', 'NN', 'O'], ['to', 'TO', 'O'], ['consumers', 'NNS', 'O'], ['to', 'TO', 'O'], ['shun', 'VB', 'O'], ['British', 'JJ', 'I-MISC'], ['lamb', 'NN', 'O'], ['until', 'IN', 'O'], ['scientists', 'NNS', 'O'], ['determine', 'VBP', 'O'], ['whether', 'IN', 'O'], ['mad', 'JJ', 'O'], ['cow', 'NN', 'O'], ['disease', 'NN', 'O'], ['can', 'MD', 'O'], ['be', 'VB', 'O'], ['transmitted', 'VBN', 'O'], ['to', 'TO', 'O'], ['sheep', 'NN', 'O'], ['.', '.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 4):\n",
    "    print(trainSentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the max sentence length\n",
    "> Let's start by clipping the longest 5%  \n",
    "> This will probably change, but we've got to start somewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLens = np.array([ len(s) for s in trainSentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKyk/h/bYaQEEYcnkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67919a8160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences longer than 37.0 words: 5 %\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "clipPct = 5\n",
    "\n",
    "maxLen = np.percentile(trainLens, 100 - clipPct)\n",
    "histLens = plt.hist(trainLens, bins=30)\n",
    "plt.vlines( maxLen, 0, max(histLens[0]), linestyles=\"dashed\")\n",
    "plt.title(\"Sentence lengths in corpus\")\n",
    "plt.hist(trainLens, bins=30)\n",
    "plt.show()\n",
    "print( \"Sentences longer than\", maxLen, \"words:\", clipPct, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  2.66500000e+03,   3.33600000e+03,   2.12800000e+03,\n",
      "         9.26000000e+02,   8.61000000e+02,   8.54000000e+02,\n",
      "         8.58000000e+02,   6.27000000e+02,   7.23000000e+02,\n",
      "         4.59000000e+02,   3.25000000e+02,   1.37000000e+02,\n",
      "         7.90000000e+01,   3.90000000e+01,   1.00000000e+01,\n",
      "         9.00000000e+00,   2.00000000e+00,   1.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00,   1.00000000e+00]), array([   1.        ,    4.73333333,    8.46666667,   12.2       ,\n",
      "         15.93333333,   19.66666667,   23.4       ,   27.13333333,\n",
      "         30.86666667,   34.6       ,   38.33333333,   42.06666667,\n",
      "         45.8       ,   49.53333333,   53.26666667,   57.        ,\n",
      "         60.73333333,   64.46666667,   68.2       ,   71.93333333,\n",
      "         75.66666667,   79.4       ,   83.13333333,   86.86666667,\n",
      "         90.6       ,   94.33333333,   98.06666667,  101.8       ,\n",
      "        105.53333333,  109.26666667,  113.        ]), <a list of 30 Patch objects>)\n",
      "Max sentence length:  113\n"
     ]
    }
   ],
   "source": [
    "print(histLens)\n",
    "print( \"Max sentence length: \", max(trainLens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['EU', 'NNP', 'I-ORG'],\n",
       "  ['rejects', 'VBZ', 'O'],\n",
       "  ['German', 'JJ', 'I-MISC'],\n",
       "  ['call', 'NN', 'O'],\n",
       "  ['to', 'TO', 'O'],\n",
       "  ['boycott', 'VB', 'O'],\n",
       "  ['British', 'JJ', 'I-MISC'],\n",
       "  ['lamb', 'NN', 'O'],\n",
       "  ['.', '.', 'O']],\n",
       " [['Peter', 'NNP', 'I-PER'], ['Blackburn', 'NNP', 'I-PER']],\n",
       " [['BRUSSELS', 'NNP', 'I-LOC'], ['1996-08-22', 'CD', 'O']],\n",
       " [['The', 'DT', 'O'],\n",
       "  ['European', 'NNP', 'I-ORG'],\n",
       "  ['Commission', 'NNP', 'I-ORG'],\n",
       "  ['said', 'VBD', 'O'],\n",
       "  ['on', 'IN', 'O'],\n",
       "  ['Thursday', 'NNP', 'O'],\n",
       "  ['it', 'PRP', 'O'],\n",
       "  ['disagreed', 'VBD', 'O'],\n",
       "  ['with', 'IN', 'O'],\n",
       "  ['German', 'JJ', 'I-MISC'],\n",
       "  ['advice', 'NN', 'O'],\n",
       "  ['to', 'TO', 'O'],\n",
       "  ['consumers', 'NNS', 'O'],\n",
       "  ['to', 'TO', 'O'],\n",
       "  ['shun', 'VB', 'O'],\n",
       "  ['British', 'JJ', 'I-MISC'],\n",
       "  ['lamb', 'NN', 'O'],\n",
       "  ['until', 'IN', 'O'],\n",
       "  ['scientists', 'NNS', 'O'],\n",
       "  ['determine', 'VBP', 'O'],\n",
       "  ['whether', 'IN', 'O'],\n",
       "  ['mad', 'JJ', 'O'],\n",
       "  ['cow', 'NN', 'O'],\n",
       "  ['disease', 'NN', 'O'],\n",
       "  ['can', 'MD', 'O'],\n",
       "  ['be', 'VB', 'O'],\n",
       "  ['transmitted', 'VBN', 'O'],\n",
       "  ['to', 'TO', 'O'],\n",
       "  ['sheep', 'NN', 'O'],\n",
       "  ['.', '.', 'O']],\n",
       " [['Germany', 'NNP', 'I-LOC'],\n",
       "  [\"'s\", 'POS', 'O'],\n",
       "  ['representative', 'NN', 'O'],\n",
       "  ['to', 'TO', 'O'],\n",
       "  ['the', 'DT', 'O'],\n",
       "  ['European', 'NNP', 'I-ORG'],\n",
       "  ['Union', 'NNP', 'I-ORG'],\n",
       "  [\"'s\", 'POS', 'O'],\n",
       "  ['veterinary', 'JJ', 'O'],\n",
       "  ['committee', 'NN', 'O'],\n",
       "  ['Werner', 'NNP', 'I-PER'],\n",
       "  ['Zwingmann', 'NNP', 'I-PER'],\n",
       "  ['said', 'VBD', 'O'],\n",
       "  ['on', 'IN', 'O'],\n",
       "  ['Wednesday', 'NNP', 'O'],\n",
       "  ['consumers', 'NNS', 'O'],\n",
       "  ['should', 'MD', 'O'],\n",
       "  ['buy', 'VB', 'O'],\n",
       "  ['sheepmeat', 'NN', 'O'],\n",
       "  ['from', 'IN', 'O'],\n",
       "  ['countries', 'NNS', 'O'],\n",
       "  ['other', 'JJ', 'O'],\n",
       "  ['than', 'IN', 'O'],\n",
       "  ['Britain', 'NNP', 'I-LOC'],\n",
       "  ['until', 'IN', 'O'],\n",
       "  ['the', 'DT', 'O'],\n",
       "  ['scientific', 'JJ', 'O'],\n",
       "  ['advice', 'NN', 'O'],\n",
       "  ['was', 'VBD', 'O'],\n",
       "  ['clearer', 'JJR', 'O'],\n",
       "  ['.', '.', 'O']]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caucasus', 'association', '1.84', '37,000', 'acknowledge', '2,096.10', 'battling', 'LIMITS', 'FI', 'DAILY', '543', 'Dai', '462', 'Asprilla', 'noise', 'Jacek', 'abstentions', 'Bodo', 'horseback', 'Available']\n",
      "Vocab size: 23626\n",
      "['SYM', 'PDT', 'RP', '\"', 'NN', 'DT', 'JJ', \"''\", '.', 'NN|SYM', 'WP$', 'UH', 'PRP', 'NNS', 'TO', 'VBG', 'WRB', 'VB', 'FW', 'RB', 'VBN', '<s>', 'RBR', ':', 'JJS', '</s>', '<unk>', 'NNP', 'RBS', ')', 'VBZ', 'NNPS', 'LS', 'CD', 'EX', 'MD', '$', ',', 'IN', 'POS', 'VBD', 'WDT', 'CC', 'JJR', 'VBP', 'WP', '(', 'PRP$']\n",
      "['I-PER', 'B-MISC', '</s>', '<unk>', 'I-MISC', 'I-ORG', 'B-ORG', 'I-LOC', 'B-LOC', '<s>', 'O']\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary - thank you w266\n",
    "# -- first attempt, leave in all numbers and maintain case\n",
    "flatData = [w for w in zip(*utils.flatten(trainSentences))]\n",
    "\n",
    "# try with lower vocab sizes... 10k, 15k, 20k\n",
    "vocab = vocabulary.Vocabulary( flatData[0])\n",
    "posTags = vocabulary.Vocabulary( flatData[1])\n",
    "nerTags = vocabulary.Vocabulary( flatData[2])\n",
    "\n",
    "print( (list(vocab.wordset)[:20]))\n",
    "print( \"Vocab size:\", vocab.size)\n",
    "print( (list(posTags.wordset)))\n",
    "print( (list(nerTags.wordset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This might be a good place to do some EDA on the vocab objects...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done playing around, define the data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class conll2003Data(object):\n",
    "    \"\"\"\n",
    "    Keep track of data and processing operations for a single CoNLL2003 data file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filePath):\n",
    "        \"\"\"\n",
    "        filePath(string): path to a CoNLL2003 raw data file for training the vocabulary\n",
    "        \"\"\"\n",
    "        # vocabulary objects for easy lookup\n",
    "        self.vocab = []\n",
    "        self.posTags = []\n",
    "        self.nerTags = []\n",
    "        \n",
    "        # read in training data\n",
    "        self.sentences = self.readFile(filePath)\n",
    "        \n",
    "    \n",
    "    def readFile( self, filePath):\n",
    "        \"\"\"\n",
    "        Read the conll2003 raw data file\n",
    "\n",
    "        filename(string) - path to conll2003 file (train, test, etc.)\n",
    "        \n",
    "        Returns: a list of lists of lists corresponding to the words, pos tags, and ner tags\n",
    "                 in each sentence\n",
    "\n",
    "        \"\"\"\n",
    "        f = open(filePath)\n",
    "        sentences = []\n",
    "        sentence = []\n",
    "        for line in f:\n",
    "            if len(line) == 0 or line.startswith(\"-DOCSTART\") or line[0] == '\\n':\n",
    "                if len(sentence) > 0:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "                continue\n",
    "            \n",
    "            # input format is [ word, pos tag, chunck tag, ner tag]\n",
    "            # we are ignoring the chunck tag\n",
    "            splits = line.strip().split(' ')\n",
    "            word = [splits[0], splits[1], splits[3]]\n",
    "            sentence.append( word)\n",
    "        \n",
    "        # don't forget the last one\n",
    "        if len(sentence) > 0:\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "        \n",
    "        return sentences\n",
    "    \n",
    "    def buildVocab( self, vocabSize=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Builds the vocabulary based on the initial data file\n",
    "        \n",
    "        vocabSize(int, default: None-all words) - max number of words to use for vocabulary\n",
    "                                                  (only used for training)\n",
    "        verbose(boolean, default: False)        - print extra info\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        flatData = [w for w in zip(*utils.flatten(self.sentences))]\n",
    "        self.vocab = vocabulary.Vocabulary( flatData[0], size=vocabSize)\n",
    "        \n",
    "        # remember these vocabs will have the <s>, </s>, and <unk> tags in there\n",
    "        # sizes need to be interpreted \"-3\" - consider replacing...\n",
    "        self.posTags = vocabulary.Vocabulary( flatData[1])\n",
    "        self.nerTags = vocabulary.Vocabulary( flatData[2])\n",
    "        \n",
    "        if verbose is True:\n",
    "            print( list(self.vocab.wordset)[:5], \"\\n\")\n",
    "            print( list(self.posTags.wordset)[:5], \"\\n\")\n",
    "            print( list(self.nerTags.wordset)[:5], \"\\n\")\n",
    "    \n",
    "    def formatPaddedData( self, sentences, clipPct = 5, verbose=False):\n",
    "        \"\"\"\n",
    "        Format the raw data by padding up to a max sentence length to be usable for training.\n",
    "        Make sure to call buildVocab first.\n",
    "        \n",
    "        sentences(list of lists of lists) - raw data from the CoNLL2003 dataset\n",
    "        clipPct(int, default: 5)          - the percentage of sentences to clip when determining the\n",
    "                                            max length to allow\n",
    "        verbose(boolean, default: False)  - print extra info\n",
    "        \n",
    "        Returns: 3 lists:   vocabulary converted to IDs, \n",
    "                            POS tags converted to IDs,\n",
    "                            NER label tag converted to IDs\n",
    "        \"\"\"\n",
    "        # get the maximum sentence length to clip down to (and pad up to) (add 2 for <s> and </s>)\n",
    "        self.maxSentLen = int(np.percentile( np.array([ len(s) for s in self.sentences]), 100.0 - clipPct)) + 2\n",
    "        \n",
    "        # we have a list of lists (sentences) of lists ([word, posTag, nerTag])\n",
    "        # parse through, pad each sentence with open and close tags, then convert to IDs\n",
    "        vocabIDs = [ self.vocab.words_to_ids( self.vocab.pad_sentence([ word[0] for word in sent])) \\\n",
    "                     for sent in sentences]\n",
    "        posIDs = [ self.posTags.words_to_ids( self.posTags.pad_sentence([word[1] for word in sent])) \\\n",
    "                   for sent in sentences]\n",
    "        nerIDs = [ self.nerTags.words_to_ids( ['<s>'] + [word[2] for word in sent] + ['</s>']) \\\n",
    "                   for sent in sentences]\n",
    "        \n",
    "        if verbose is True:\n",
    "            print( vocabIDs[:5], \"\\n\")\n",
    "            print( posIDs[:5], \"\\n\")\n",
    "            print( nerIDs[:5], \"\\n\")\n",
    "\n",
    "        # pad and clip so all sentences are the same length\n",
    "        vocabIDs = sequence.pad_sequences( vocabIDs, maxlen = self.maxSentLen)\n",
    "        posIDs = sequence.pad_sequences( posIDs, maxlen = self.maxSentLen)\n",
    "        nerIDs = sequence.pad_sequences( nerIDs, maxlen = self.maxSentLen, \n",
    "                                         value=self.nerTags.word_to_id['O'])\n",
    "        \n",
    "        return vocabIDs, posIDs, nerIDs\n",
    "    \n",
    "    #\n",
    "    # I think it makes the most sense to generate all the training data up front.\n",
    "    # If we had more data or planned to augment on the fly, it would make more sense to \n",
    "    # use a generator.\n",
    "    # \n",
    "    # window generation notes\n",
    "    #     Don't cross sentence boundaries.\n",
    "    #     This means that each sentence will be padded with (windowLength // 2) open/close\n",
    "    #     tags on each end. Also, when we hit a <s> tag after a </s> tag, start the new\n",
    "    #     window there rather than continuing to slide.\n",
    "    # \n",
    "    def formatWindowedData( self, sentences, windowLength=9, verbose=False):\n",
    "        \"\"\"\n",
    "        Format the raw data by blocking it into context windows of a fixed length corresponding \n",
    "        to the single target NER tag of the central word.\n",
    "        Make sure to call buildVocab first.\n",
    "        \n",
    "        sentences(list of lists of lists) - raw data from the CoNLL2003 dataset\n",
    "        windowLength(int, default: 9)     - The length of the context window\n",
    "                    NOTE - windowLength must be odd to have a central word. If itsn't, 1 will be added.\n",
    "        verbose(boolean, default: False)  - print extra info\n",
    "        \n",
    "        Returns: 3 numpy arrays: vocabulary training data windowed and converted to IDs, \n",
    "                                 POS tags windowed and converted to IDs,\n",
    "                                 NER label tags converted to IDs\n",
    "        \"\"\"\n",
    "        pads = windowLength // 2\n",
    "        \n",
    "        # we have a list of lists (sentences) of lists ([word, posTag, nerTag])\n",
    "        # parse through, pad each sentence with pads open and close tags, then convert to IDs\n",
    "        vocabIDs = [ self.vocab.words_to_ids( [\"<s>\"] * pads + [word[0] for word in sent] + [\"</s>\"] * pads) \\\n",
    "                     for sent in sentences]\n",
    "        posIDs = [ self.posTags.words_to_ids( [\"<s>\"] * pads + [word[1] for word in sent] + [\"</s>\"] * pads) \\\n",
    "                   for sent in sentences]\n",
    "        nerIDs = [ self.nerTags.words_to_ids( [\"<s>\"] * pads + [word[2] for word in sent] + [\"</s>\"] * pads) \\\n",
    "                   for sent in sentences]\n",
    "        \n",
    "        if verbose is True:\n",
    "            print( vocabIDs[:5], \"\\n\")\n",
    "            print( posIDs[:5], \"\\n\")\n",
    "            print( nerIDs[:5], \"\\n\")\n",
    "        \n",
    "        assert(len(vocabIDs) == len(posIDs) and len(posIDs) == len(nerIDs))\n",
    "        \n",
    "        # build the data to train on by sliding the window across each sentence\n",
    "        # at this point, all 3 lists are the same size, so we can run through them all at once\n",
    "        featsVocab, featsPOS, featsNER = [], [], []\n",
    "        for sentID in range( len(vocabIDs)):\n",
    "            sent = vocabIDs[sentID]\n",
    "            sentPOS = posIDs[sentID]\n",
    "            sentNER = nerIDs[sentID]\n",
    "            \n",
    "            for ID in range( len(sent) - windowLength + 1):\n",
    "                featsVocab.append( sent[ID:ID + windowLength])\n",
    "                featsPOS.append( sentPOS[ID:ID + windowLength])\n",
    "                featsNER.append( sentNER[ID + windowLength // 2])\n",
    "        \n",
    "        return np.array(featsVocab), \\\n",
    "               np.array(featsPOS), \\\n",
    "               np.array(featsNER)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the windowing functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = trainSentences\n",
    "windowLength = 9\n",
    "pads = windowLength // 2\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 959, 11985, 235, 764, 8, 4149, 211, 6184, 3, 1, 1, 1, 1], [0, 0, 0, 0, 734, 2070, 1, 1, 1, 1], [0, 0, 0, 0, 1381, 136, 1, 1, 1, 1]] \n",
      "\n",
      "[[0, 0, 0, 0, 3, 22, 8, 4, 17, 13, 8, 4, 11, 1, 1, 1, 1], [0, 0, 0, 0, 3, 3, 1, 1, 1, 1], [0, 0, 0, 0, 3, 5, 1, 1, 1, 1]] \n",
      "\n",
      "[[0, 0, 0, 0, 5, 3, 7, 3, 3, 3, 7, 3, 3, 1, 1, 1, 1], [0, 0, 0, 0, 4, 4, 1, 1, 1, 1], [0, 0, 0, 0, 6, 3, 1, 1, 1, 1]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we have a list of lists (sentences) of lists ([word, posTag, nerTag])\n",
    "# parse through, pad each sentence with open and close tags, then convert to IDs\n",
    "vocabIDs = [ vocab.words_to_ids( [\"<s>\"] * pads + [word[0] for word in sent] + [\"</s>\"] * pads) \\\n",
    "             for sent in sentences]\n",
    "posIDs = [ posTags.words_to_ids( [\"<s>\"] * pads + [word[1] for word in sent] + [\"</s>\"] * pads) \\\n",
    "           for sent in sentences]\n",
    "nerIDs = [ nerTags.words_to_ids( [\"<s>\"] * pads + [word[2] for word in sent] + [\"</s>\"] * pads) \\\n",
    "           for sent in sentences]\n",
    "\n",
    "if verbose is True:\n",
    "    print( vocabIDs[:3], \"\\n\")\n",
    "    print( posIDs[:3], \"\\n\")\n",
    "    print( nerIDs[:3], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 959, 11985, 235, 764, 8, 4149, 211, 6184, 3, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 3, 22, 8, 4, 17, 13, 8, 4, 11, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 5, 3, 7, 3, 3, 3, 7, 3, 3, 1, 1, 1, 1] \n",
      "\n",
      "[0, 0, 0, 0, 734, 2070, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 3, 3, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 4, 4, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "[0, 0, 0, 0, 959, 11985, 235, 764, 8]\n",
      "[0, 0, 0, 0, 3, 22, 8, 4, 17]\n",
      "Center NER tag: 5\n",
      "Center ID: 959 \n",
      "\n",
      "[0, 0, 0, 959, 11985, 235, 764, 8, 4149]\n",
      "[0, 0, 0, 3, 22, 8, 4, 17, 13]\n",
      "Center NER tag: 3\n",
      "Center ID: 11985 \n",
      "\n",
      "[0, 0, 959, 11985, 235, 764, 8, 4149, 211]\n",
      "[0, 0, 3, 22, 8, 4, 17, 13, 8]\n",
      "Center NER tag: 7\n",
      "Center ID: 235 \n",
      "\n",
      "[0, 959, 11985, 235, 764, 8, 4149, 211, 6184]\n",
      "[0, 3, 22, 8, 4, 17, 13, 8, 4]\n",
      "Center NER tag: 3\n",
      "Center ID: 764 \n",
      "\n",
      "[959, 11985, 235, 764, 8, 4149, 211, 6184, 3]\n",
      "[3, 22, 8, 4, 17, 13, 8, 4, 11]\n",
      "Center NER tag: 3\n",
      "Center ID: 8 \n",
      "\n",
      "[11985, 235, 764, 8, 4149, 211, 6184, 3, 1]\n",
      "[22, 8, 4, 17, 13, 8, 4, 11, 1]\n",
      "Center NER tag: 3\n",
      "Center ID: 4149 \n",
      "\n",
      "[235, 764, 8, 4149, 211, 6184, 3, 1, 1]\n",
      "[8, 4, 17, 13, 8, 4, 11, 1, 1]\n",
      "Center NER tag: 7\n",
      "Center ID: 211 \n",
      "\n",
      "[764, 8, 4149, 211, 6184, 3, 1, 1, 1]\n",
      "[4, 17, 13, 8, 4, 11, 1, 1, 1]\n",
      "Center NER tag: 3\n",
      "Center ID: 6184 \n",
      "\n",
      "[8, 4149, 211, 6184, 3, 1, 1, 1, 1]\n",
      "[17, 13, 8, 4, 11, 1, 1, 1, 1]\n",
      "Center NER tag: 3\n",
      "Center ID: 3 \n",
      "\n",
      "[0, 0, 0, 0, 734, 2070, 1, 1, 1]\n",
      "[0, 0, 0, 0, 3, 3, 1, 1, 1]\n",
      "Center NER tag: 4\n",
      "Center ID: 734 \n",
      "\n",
      "[0, 0, 0, 734, 2070, 1, 1, 1, 1]\n",
      "[0, 0, 0, 3, 3, 1, 1, 1, 1]\n",
      "Center NER tag: 4\n",
      "Center ID: 2070 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the data to train on by sliding the window across each sentence\n",
    "# at this point, all 3 lists are the same size, so we can run through them all at once\n",
    "featsVocab, featsPOS, featsNER = [], [], []\n",
    "for sentID in range( len(vocabIDs)):\n",
    "    sent = vocabIDs[sentID]\n",
    "    sentPOS = posIDs[sentID]\n",
    "    sentNER = nerIDs[sentID]\n",
    "    for ID in range( len(sent) - windowLength + 1):\n",
    "        featsVocab.append( sent[ID:ID + windowLength])\n",
    "        featsPOS.append( sentPOS[ID:ID + windowLength])\n",
    "        featsNER.append( sentNER[ID + windowLength // 2])\n",
    "\n",
    "showID = 0\n",
    "print( vocabIDs[showID])\n",
    "print( posIDs[showID])\n",
    "print( nerIDs[showID], '\\n')\n",
    "print( vocabIDs[showID+1])\n",
    "print( posIDs[showID+1])\n",
    "print( nerIDs[showID+1])\n",
    "print( '\\n')\n",
    "for i in range(11):\n",
    "    print( featsVocab[i])\n",
    "    print( featsPOS[i])\n",
    "    print( \"Center NER tag:\", featsNER[i])\n",
    "    print( \"Center ID:\", featsVocab[i][windowLength // 2], '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 959, 11985, 235, 764, 8, 4149, 211, 6184, 3, 1, 1, 1, 1], [0, 0, 0, 0, 734, 2070, 1, 1, 1, 1], [0, 0, 0, 0, 1381, 136, 1, 1, 1, 1], [0, 0, 0, 0, 20, 228, 457, 15, 14, 68, 37, 8129, 26, 235, 4150, 8, 2478, 8, 11986, 211, 6184, 409, 3544, 2071, 501, 1791, 1922, 653, 289, 41, 8130, 8, 1923, 3, 1, 1, 1, 1], [0, 0, 0, 0, 116, 16, 3112, 8, 5, 228, 487, 16, 2752, 1060, 8131, 8132, 15, 14, 73, 2478, 259, 876, 8133, 28, 539, 126, 114, 124, 409, 5, 2479, 4150, 21, 11987, 3, 1, 1, 1, 1]] \n",
      "\n",
      "[[0, 0, 0, 0, 3, 22, 8, 4, 17, 13, 8, 4, 11, 1, 1, 1, 1], [0, 0, 0, 0, 3, 3, 1, 1, 1, 1], [0, 0, 0, 0, 3, 5, 1, 1, 1, 1], [0, 0, 0, 0, 7, 3, 3, 10, 6, 3, 18, 10, 6, 8, 4, 17, 9, 17, 13, 8, 4, 6, 9, 27, 6, 8, 4, 4, 28, 13, 14, 17, 4, 11, 1, 1, 1, 1], [0, 0, 0, 0, 3, 25, 4, 17, 7, 3, 3, 25, 8, 4, 3, 3, 10, 6, 3, 9, 28, 13, 4, 6, 9, 8, 6, 3, 6, 7, 8, 4, 10, 36, 11, 1, 1, 1, 1]] \n",
      "\n",
      "[[0, 0, 0, 0, 5, 3, 7, 3, 3, 3, 7, 3, 3, 1, 1, 1, 1], [0, 0, 0, 0, 4, 4, 1, 1, 1, 1], [0, 0, 0, 0, 6, 3, 1, 1, 1, 1], [0, 0, 0, 0, 3, 5, 5, 3, 3, 3, 3, 3, 3, 7, 3, 3, 3, 3, 3, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1], [0, 0, 0, 0, 6, 3, 3, 3, 3, 5, 5, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1]] \n",
      "\n",
      "Windowed sentence length: 9\n",
      "[[    0     0     0     0   959 11985   235   764     8]\n",
      " [    0     0     0   959 11985   235   764     8  4149]\n",
      " [    0     0   959 11985   235   764     8  4149   211]\n",
      " [    0   959 11985   235   764     8  4149   211  6184]\n",
      " [  959 11985   235   764     8  4149   211  6184     3]\n",
      " [11985   235   764     8  4149   211  6184     3     1]\n",
      " [  235   764     8  4149   211  6184     3     1     1]\n",
      " [  764     8  4149   211  6184     3     1     1     1]\n",
      " [    8  4149   211  6184     3     1     1     1     1]\n",
      " [    0     0     0     0   734  2070     1     1     1]] \n",
      " [5 3 7 3 3 3 7 3 3 4]\n"
     ]
    }
   ],
   "source": [
    "#clipPct = 5\n",
    "windowLength = 9\n",
    "testNumSents = 5000\n",
    "\n",
    "# read in training data\n",
    "vocabData = conll2003Data( TRAIN_FILE)\n",
    "\n",
    "# FOR TESTING\n",
    "#vocabData.sentences = vocabData.sentences[:testNumSents]\n",
    "\n",
    "# not yet using the pos tags\n",
    "# try with lower vocab sizes... 10k, 15k, 20k\n",
    "#vocabData.buildVocab( vocabSize=20000)\n",
    "vocabData.buildVocab( vocabSize=20000)\n",
    "trainX, _, trainY = vocabData.formatWindowedData( vocabData.sentences, \n",
    "                                                  windowLength=windowLength,\n",
    "                                                  verbose=True)\n",
    "\n",
    "# check the first few windows\n",
    "print( \"Windowed sentence length:\", len(trainX[0]))\n",
    "print( trainX[:10], '\\n', trainY[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 452, 19, 2, 9044, 8349, 128, 7588, 1828, 16059, 10368, 3, 1, 1, 1, 1], [0, 0, 0, 0, 212, 2749, 1, 1, 1, 1], [0, 0, 0, 0, 292, 905, 6372, 3615, 6347, 266, 155, 17, 1373, 14, 93, 32, 2530, 58, 3173, 29, 42, 274, 12, 1732, 371, 7, 54, 281, 8, 255, 72, 25, 5, 549, 6, 5, 2191, 467, 3, 1, 1, 1, 1], [0, 0, 0, 0, 2501, 1209, 14, 426, 4, 1767, 4, 496, 41, 17973, 32, 859, 2761, 1500, 4, 7170, 12, 1820, 129, 519, 7, 14, 302, 215, 2815, 183, 61, 17, 188, 115, 7, 56, 19891, 149, 77, 2531, 3, 1, 1, 1, 1], [0, 0, 0, 0, 932, 5882, 3173, 67, 17, 3338, 14, 5, 739, 551, 25, 2, 5879, 4, 2530, 3589, 56, 49, 274, 29, 6350, 371, 111, 234, 4479, 67, 17, 2, 26, 134, 2, 2841, 10895, 450, 87, 17, 3338, 3, 1, 1, 1, 1]] \n",
      "\n",
      "[[0, 0, 0, 0, 3, 23, 3, 3, 6, 3, 3, 3, 3, 4, 11, 1, 1, 1, 1], [0, 0, 0, 0, 3, 5, 1, 1, 1, 1], [0, 0, 0, 0, 3, 3, 4, 3, 3, 10, 5, 6, 5, 6, 3, 6, 3, 10, 3, 6, 7, 4, 16, 5, 9, 6, 5, 9, 17, 13, 6, 6, 7, 4, 6, 7, 4, 4, 11, 1, 1, 1, 1], [0, 0, 0, 0, 26, 4, 6, 4, 12, 15, 12, 28, 13, 8, 6, 4, 9, 3, 12, 3, 16, 3, 7, 10, 31, 6, 4, 6, 3, 10, 31, 6, 14, 4, 6, 26, 8, 4, 6, 3, 11, 1, 1, 1, 1], [0, 0, 0, 0, 6, 21, 3, 31, 6, 5, 6, 7, 4, 4, 6, 3, 3, 12, 3, 10, 26, 8, 4, 6, 5, 22, 6, 21, 10, 31, 6, 5, 6, 3, 27, 3, 3, 21, 5, 6, 5, 11, 1, 1, 1, 1]] \n",
      "\n",
      "[[0, 0, 0, 0, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1], [0, 0, 0, 0, 6, 3, 1, 1, 1, 1], [0, 0, 0, 0, 7, 7, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 5, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1], [0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 5, 3, 5, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 1, 1, 1, 1], [0, 0, 0, 0, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 4, 4, 3, 3, 3, 3, 3, 1, 1, 1, 1]] \n",
      "\n",
      "Padded sentence length: 9\n",
      "[[    0     0     0     0   452    19     2  9044  8349]\n",
      " [    0     0     0   452    19     2  9044  8349   128]\n",
      " [    0     0   452    19     2  9044  8349   128  7588]\n",
      " [    0   452    19     2  9044  8349   128  7588  1828]\n",
      " [  452    19     2  9044  8349   128  7588  1828 16059]\n",
      " [   19     2  9044  8349   128  7588  1828 16059 10368]\n",
      " [    2  9044  8349   128  7588  1828 16059 10368     3]\n",
      " [ 9044  8349   128  7588  1828 16059 10368     3     1]\n",
      " [ 8349   128  7588  1828 16059 10368     3     1     1]\n",
      " [  128  7588  1828 16059 10368     3     1     1     1]\n",
      " [ 7588  1828 16059 10368     3     1     1     1     1]\n",
      " [    0     0     0     0   212  2749     1     1     1]] \n",
      " [3 3 5 3 3 3 3 3 3 3 3 6]\n"
     ]
    }
   ],
   "source": [
    "# read in dev data\n",
    "devSents = vocabData.readFile( DEV_FILE)\n",
    "\n",
    "# FOR TESTING\n",
    "#devSents = devSents[:testNumSents]\n",
    "\n",
    "# not yet using the pos tags\n",
    "devX, _, devY = vocabData.formatWindowedData( devSents, \n",
    "                                              windowLength=windowLength,\n",
    "                                              verbose=True)\n",
    "\n",
    "print( \"Padded sentence length:\", len(devX[0]))\n",
    "print( devX[:12], '\\n', devY[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 127, 19, 2, 2, 2, 1436, 4, 2, 471, 2, 15306, 3, 1, 1, 1, 1], [0, 0, 0, 0, 2, 2, 1, 1, 1, 1], [0, 0, 0, 0, 2, 4, 167, 1124, 12138, 2, 1, 1, 1, 1], [0, 0, 0, 0, 216, 531, 5, 1136, 6, 56, 5300, 206, 859, 26, 9, 9010, 934, 181, 77, 1674, 7, 9, 957, 1772, 467, 149, 14, 93, 3, 1, 1, 1, 1], [0, 0, 0, 0, 108, 202, 1269, 56, 6568, 13066, 186, 7, 5, 81, 149, 6, 5, 139, 4, 6959, 8, 9, 3245, 750, 1088, 8, 2, 2, 3, 1, 1, 1, 1]] \n",
      "\n",
      "[[0, 0, 0, 0, 4, 23, 3, 13, 3, 3, 12, 3, 6, 7, 4, 11, 1, 1, 1, 1], [0, 0, 0, 0, 3, 3, 1, 1, 1, 1], [0, 0, 0, 0, 3, 12, 3, 3, 29, 5, 1, 1, 1, 1], [0, 0, 0, 0, 3, 10, 7, 4, 6, 26, 8, 3, 4, 6, 7, 8, 5, 27, 6, 3, 6, 7, 3, 3, 4, 4, 6, 3, 11, 1, 1, 1, 1], [0, 0, 0, 0, 16, 3, 10, 26, 4, 13, 18, 6, 7, 4, 4, 6, 7, 4, 12, 21, 17, 7, 4, 5, 4, 17, 9, 3, 11, 1, 1, 1, 1]] \n",
      "\n",
      "[[0, 0, 0, 0, 3, 3, 6, 3, 3, 3, 3, 4, 3, 3, 3, 3, 1, 1, 1, 1], [0, 0, 0, 0, 4, 4, 1, 1, 1, 1], [0, 0, 0, 0, 6, 3, 6, 6, 6, 3, 1, 1, 1, 1], [0, 0, 0, 0, 6, 3, 3, 3, 3, 3, 7, 7, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1], [0, 0, 0, 0, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 1, 1, 1, 1]] \n",
      "\n",
      "Padded sentence length: 9\n",
      "[[    0     0     0     0   127    19     2     2     2]\n",
      " [    0     0     0   127    19     2     2     2  1436]\n",
      " [    0     0   127    19     2     2     2  1436     4]\n",
      " [    0   127    19     2     2     2  1436     4     2]\n",
      " [  127    19     2     2     2  1436     4     2   471]\n",
      " [   19     2     2     2  1436     4     2   471     2]\n",
      " [    2     2     2  1436     4     2   471     2 15306]\n",
      " [    2     2  1436     4     2   471     2 15306     3]\n",
      " [    2  1436     4     2   471     2 15306     3     1]\n",
      " [ 1436     4     2   471     2 15306     3     1     1]\n",
      " [    4     2   471     2 15306     3     1     1     1]\n",
      " [    2   471     2 15306     3     1     1     1     1]] \n",
      " [3 3 6 3 3 3 3 4 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# read in the test data\n",
    "testSents = vocabData.readFile( TEST_FILE)\n",
    "\n",
    "# not yet using the pos tags\n",
    "testX, _, testY = vocabData.formatWindowedData( testSents, \n",
    "                                                windowLength=windowLength,\n",
    "                                                verbose=True)\n",
    "\n",
    "print( \"Padded sentence length:\", len(testX[0]))\n",
    "print( testX[:12], '\\n', testY[:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -  \n",
    "### Investigate NER tags\n",
    "> We can see that the dev set doesn't have `B-LOG` or `B-ORG`.  \n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'I-PER', 'I-ORG', 'I-LOC', 'I-MISC', 'B-MISC', 'B-ORG', 'B-LOC']\n",
      "{'I-PER', 'B-MISC', '</s>', '<unk>', 'I-MISC', 'I-ORG', 'B-ORG', 'I-LOC', 'B-LOC', '<s>', 'O'}\n"
     ]
    }
   ],
   "source": [
    "s = set([i for i in trainY.flatten()])\n",
    "print(vocabData.nerTags.ids_to_words(s))\n",
    "print(vocabData.nerTags.wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'I-PER', 'I-ORG', 'I-LOC', 'I-MISC', 'B-MISC']\n",
      "{'I-PER', 'B-MISC', '</s>', '<unk>', 'I-MISC', 'I-ORG', 'B-ORG', 'I-LOC', 'B-LOC', '<s>', 'O'}\n"
     ]
    }
   ],
   "source": [
    "s = set([i for i in devY.flatten()])\n",
    "print(vocabData.nerTags.ids_to_words(s))\n",
    "print(vocabData.nerTags.wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'I-PER', 'I-ORG', 'I-LOC', 'I-MISC', 'B-MISC', 'B-ORG', 'B-LOC']\n",
      "{'I-PER', 'B-MISC', '</s>', '<unk>', 'I-MISC', 'I-ORG', 'B-ORG', 'I-LOC', 'B-LOC', '<s>', 'O'}\n"
     ]
    }
   ],
   "source": [
    "s = set([i for i in testY.flatten()])\n",
    "print(vocabData.nerTags.ids_to_words(s))\n",
    "print(vocabData.nerTags.wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'O': 169578, 'I-PER': 11128, 'I-ORG': 10001, 'I-LOC': 8286, 'I-MISC': 4556, 'B-MISC': 37, 'B-ORG': 24, 'B-LOC': 11})\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print( vocabData.nerTags.unigram_counts)\n",
    "print( len(vocabData.nerTags.unigram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 O \t 169578\n",
      "4 I-PER \t 11128\n",
      "5 I-ORG \t 10001\n",
      "6 I-LOC \t 8286\n",
      "7 I-MISC \t 4556\n",
      "8 B-MISC \t 37\n",
      "9 B-ORG \t 24\n",
      "10 B-LOC \t 11\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "bc = Counter()\n",
    "a = []\n",
    "flatX = trainX.flatten()\n",
    "flatY = trainY.flatten()\n",
    "for j, i in enumerate(flatY):\n",
    "    if i == 10:\n",
    "        a += [j]\n",
    "        #print(vocabData.vocab.id_to_word[flatX[j]])\n",
    "    bc[int(i)] += 1\n",
    "\n",
    "for key, v in sorted(bc.items(), key=lambda i: i[0]):\n",
    "    print( key, vocabData.nerTags.id_to_word[int(key)], '\\t', v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1832589\n",
      "203621\n"
     ]
    }
   ],
   "source": [
    "print(len(flatX))\n",
    "print(len(flatY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1819, 126796, 126806, 126815, 126825, 126834, 126842, 126852, 126861, 126870, 160096]\n",
      "<s> ['to', 'review', 'his', '<s>', '<s>', 'But', 'Fischler', 'agreed']\n",
      "B-LOC ['O', 'O', 'I-LOC', 'I-LOC', 'B-LOC', 'O', 'O', 'I-LOC']\n",
      "lock [',', 'but', 'they', 'could', 'lock', 'horns', 'in', 'the']\n",
      "B-LOC ['O', 'O', 'O', 'I-LOC', 'B-LOC', 'O', 'O', 'O']\n",
      "in ['they', 'could', 'lock', 'horns', 'in', 'the', 'semis', '.']\n",
      "B-LOC ['O', 'O', 'O', 'I-LOC', 'B-LOC', 'O', 'O', 'O']\n",
      "the ['could', 'lock', 'horns', 'in', 'the', 'semis', '.', '</s>']\n",
      "B-LOC ['O', 'O', 'O', 'I-LOC', 'B-LOC', 'O', 'O', 'O']\n",
      ". ['horns', 'in', 'the', 'semis', '.', '</s>', '</s>', 'lock']\n",
      "B-LOC ['O', 'O', 'I-LOC', 'I-LOC', 'B-LOC', 'O', 'O', 'O']\n",
      "</s> ['in', 'the', 'semis', '.', '</s>', '</s>', '</s>', 'horns']\n",
      "B-LOC ['O', 'O', 'O', 'I-LOC', 'B-LOC', 'O', 'O', 'O']\n",
      "</s> ['in', 'the', 'semis', '.', '</s>', '</s>', '</s>', '</s>']\n",
      "B-LOC ['O', 'O', 'O', 'I-LOC', 'B-LOC', 'O', 'O', 'O']\n",
      "Agassi ['<s>', '<s>', 'Olympic', 'champion', 'Agassi', 'meets', 'Karim', '<s>']\n",
      "B-LOC ['O', 'O', 'I-LOC', 'I-LOC', 'B-LOC', 'O', 'O', 'O']\n",
      "meets ['<s>', 'Olympic', 'champion', 'Agassi', 'meets', 'Karim', 'Alami', '<s>']\n",
      "B-LOC ['O', 'O', 'O', 'I-LOC', 'B-LOC', 'O', 'O', 'O']\n",
      "Karim ['Olympic', 'champion', 'Agassi', 'meets', 'Karim', 'Alami', 'of', '<s>']\n",
      "B-LOC ['O', 'O', 'O', 'I-LOC', 'B-LOC', 'O', 'O', 'O']\n",
      "charged ['in', 'custody', 'on', 'Wednesday', 'charged', 'with', 'attempted', 'murder']\n",
      "B-LOC ['O', 'O', 'O', 'I-LOC', 'B-LOC', 'I-LOC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "for j in a:\n",
    "    print( vocabData.vocab.id_to_word[trainX[j]], vocabData.vocab.ids_to_words(flatX[j-4:j+4]))\n",
    "    print( vocabData.nerTags.id_to_word[flatY[j]], vocabData.nerTags.ids_to_words(flatY[j-4:j+4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# capsule layers from Xifeng Guo \n",
    "# https://github.com/XifengGuo/CapsNet-Keras\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape y from all labels to a row per class\n",
    "trainY_cat = to_categorical(trainY.astype('float32'))\n",
    "# num_classes is required because the dev set doesn't have all the tags represented\n",
    "devY_cat = to_categorical(devY.astype('float32'), num_classes=trainY_cat.shape[1])\n",
    "testY_cat = to_categorical(testY.astype('float32'), num_classes=trainY_cat.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainY_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 0\n",
      "2 0\n",
      "3 169578\n",
      "4 180706\n",
      "5 190707\n",
      "6 198993\n",
      "7 203549\n",
      "8 203586\n",
      "9 203610\n",
      "10 203621\n",
      "New shape of train: (203621, 11)\n",
      "New shape of dev: (51362, 11)\n",
      "New shape of test: (46435, 11)\n"
     ]
    }
   ],
   "source": [
    "# look at the 1-hot representation\n",
    "totes = 0\n",
    "for n in range(vocabData.nerTags.size):\n",
    "    for i in trainY_cat:\n",
    "        if i[n] == 1:\n",
    "            totes += 1\n",
    "    print(n, totes)\n",
    "\n",
    "print( \"New shape of train:\", trainY_cat.shape)\n",
    "print( \"New shape of dev:\", devY_cat.shape)\n",
    "print( \"New shape of test:\", testY_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a few extra tags in the NER vocab for padding and such. We'll shrink the vectors and remove these unnecessary targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainY_cat = np.array(list(map( lambda i: np.array(i[3:], dtype=np.float), trainY_cat)), dtype=np.float)\n",
    "devY_cat = np.array(list(map( lambda i: np.array(i[3:], dtype=np.float), devY_cat)), dtype=np.float)\n",
    "testY_cat = np.array(list(map( lambda i: np.array(i[3:], dtype=np.float), testY_cat)), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 169578\n",
      "1 180706\n",
      "2 190707\n",
      "3 198993\n",
      "4 203549\n",
      "5 203586\n",
      "6 203610\n",
      "7 203621\n",
      "New shape of train: (203621, 8)\n",
      "New shape of dev: (51362, 8)\n"
     ]
    }
   ],
   "source": [
    "# Make sure it worked\n",
    "totes = 0\n",
    "for n in range(trainY_cat.shape[1]):\n",
    "    for i in trainY_cat:\n",
    "        if i[n] == 1:\n",
    "            totes += 1\n",
    "    print(n, totes)\n",
    "\n",
    "print( \"New shape of train:\", trainY_cat.shape)\n",
    "print( \"New shape of dev:\", devY_cat.shape)\n",
    "#print( \"New shape of test:\", testY_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabData.vocab.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters\n",
    "max_features = vocabData.vocab.size\n",
    "maxlen = trainX.shape[1]\n",
    "ner_classes = trainY_cat.shape[1]\n",
    "embed_dim = 50\n",
    "num_routing = 3\n",
    "\n",
    "save_dir = './result'\n",
    "batch_size = 100\n",
    "debug = 2\n",
    "epochs = 5\n",
    "dropout_p = 0.25\n",
    "embed_dropout = 0.25\n",
    "lam_recon = 0.0005\n",
    "\n",
    "#Load train and test data\n",
    "#(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "#x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "#x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed (?, 9, 50)\n",
      "ner_caps (?, 8, 16)\n",
      "out_caps (?, 8)\n"
     ]
    }
   ],
   "source": [
    "#from keras import Sequential\n",
    "#Build embedding and convolutional layers\n",
    "\n",
    "x = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, embed_dim, input_length=maxlen, embeddings_initializer=\"random_uniform\" )(x)\n",
    "\n",
    "# only needed for conv2D (ie without conv1D...)\n",
    "#embed = Reshape( ( maxlen, embed_dim, 1))(embed)\n",
    "\n",
    "#add dropout here... spatial1d I think it is...\n",
    "#embed = SpatialDropout1D(embed_dropout)(embed)\n",
    "\n",
    "# maybe add this back in!! - make sure to consider the window length\n",
    "#conv1 = Conv1D( filters=256, kernel_size=3, strides=1, padding='valid', \n",
    "#                      activation='relu', name='conv1')(embed)\n",
    "\n",
    "print( \"embed\", embed.get_shape())\n",
    "    \n",
    "# Layer 2: Conv2D layer with `squash` activation, then reshape to \n",
    "# kernel_size should be smaller than window size... maybe half of window size?\n",
    "# [None, num_capsule, dim_vector]\n",
    "primarycaps = PrimaryCap( embed, dim_capsule=8, \n",
    "                          n_channels=32, kernel_size=(windowLength // 2),#, embed_dim),#<-- make it like 1D windowLength // 2, \n",
    "                          strides=1, padding='valid')\n",
    "\n",
    "# Layer 3: Capsule layer. Routing algorithm works here.\n",
    "ner_caps = CapsuleLayer( num_capsule=ner_classes, dim_capsule=16, \n",
    "                         routings=num_routing, name='nercaps')(primarycaps)\n",
    "\n",
    "\n",
    "# Layer 4: This is an auxiliary layer to replace each capsule with its length. \n",
    "# Just to match the true label's shape.\n",
    "# If using tensorflow, this will not be necessary. :)\n",
    "print( \"ner_caps\", ner_caps.get_shape())\n",
    "out_caps = Length(name='out_caps')(ner_caps)\n",
    "print( \"out_caps\", out_caps.get_shape())\n",
    "\n",
    "# Decoder network. - probably get the dims right then flatten it\n",
    "\n",
    "\n",
    "#not these...\n",
    "#y = Reshape( ( maxlen * ner_classes,), input_shape=( trainY.shape[1], trainY.shape[2],))\n",
    "#y = Flatten( )(y)\n",
    "#y = KB.reshape( y, ( maxlen * ner_classes,))\n",
    "#print(\"y shape:\", y.)\n",
    "#print(ner_caps.shape[1], ner_caps.shape[2], ner_caps.shape[1] * ner_caps.shape[2])\n",
    "#ner_caps = Reshape((ner_caps.shape[1] * ner_caps.shape[2],))(ner_caps)\n",
    "\n",
    "\n",
    "#y = Input(shape=(ner_classes,))\n",
    "\n",
    "#masked = Mask()([ner_caps, y])  # The true label is used to mask the output of capsule layer.\n",
    "#x_recon = Dense(512, activation='relu')(y)#(masked)\n",
    "#x_recon = Dense(1024, activation='relu')(x_recon)\n",
    "#x_recon = Dense(maxlen, activation='sigmoid')(x_recon)\n",
    "\n",
    "# maybe change to a sampled softmax!\n",
    "#x_recon = Dense( max_features, activation='softmax')(x_recon)\n",
    "\n",
    "\n",
    "# x_recon = layers.Reshape(target_shape=[1], name='out_recon')(x_recon)\n",
    "\n",
    "capsmodel = Model([x], [out_caps])\n",
    "#capsmodel = Model([x, y], [out_caps, x_recon])\n",
    "#capsmodel = Model([y], [x_recon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 9, 50)             1000000   \n",
      "_________________________________________________________________\n",
      "primarycap_conv2d (Conv1D)   (None, 6, 256)            51456     \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 192, 8)            0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 192, 8)            0         \n",
      "_________________________________________________________________\n",
      "nercaps (CapsuleLayer)       (None, 8, 16)             196608    \n",
      "_________________________________________________________________\n",
      "out_caps (Length)            (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 1,248,064\n",
      "Trainable params: 1,248,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Saving weights and logging\n",
    "log = callbacks.CSVLogger(save_dir + '/log.csv')\n",
    "tb = callbacks.TensorBoard(log_dir=save_dir + '/tensorboard-logs', \n",
    "                           batch_size=batch_size, histogram_freq=debug)\n",
    "checkpoint = callbacks.ModelCheckpoint(save_dir + '/weights-{epoch:02d}.h5', \n",
    "                                       save_best_only=True, \n",
    "                                       save_weights_only=True, \n",
    "                                       verbose=1)\n",
    "#lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
    "\n",
    "#margin_loss\n",
    "def margin_loss(y_true, y_pred):\n",
    "    L = y_true * KB.square(KB.maximum(0., 0.9 - y_pred)) + 0.5 * (1 - y_true) * KB.square(KB.maximum(0., y_pred - 0.1))\n",
    "    return KB.mean(KB.sum(L, 1))\n",
    "\n",
    "capsmodel.summary()\n",
    "\n",
    "#Save a png of the model shapes and flow\n",
    "#plot_model(capsmodel, to_file=save_dir + '/reuters-model.png', show_shapes=True)\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#opt = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 203621 samples, validate on 51362 samples\n",
      "Epoch 1/5\n",
      "203621/203621 [==============================] - 121s 595us/step - loss: 0.1250 - acc: 0.8823 - val_loss: 0.0298 - val_acc: 0.9622\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02979, saving model to ./result/weights-01.h5\n",
      "Epoch 2/5\n",
      "203621/203621 [==============================] - 121s 593us/step - loss: 0.0100 - acc: 0.9887 - val_loss: 0.0254 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02979 to 0.02537, saving model to ./result/weights-02.h5\n",
      "Epoch 3/5\n",
      "203621/203621 [==============================] - 121s 592us/step - loss: 0.0042 - acc: 0.9953 - val_loss: 0.0264 - val_acc: 0.9670\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      "203621/203621 [==============================] - 124s 608us/step - loss: 0.0026 - acc: 0.9972 - val_loss: 0.0268 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      "203621/203621 [==============================] - 122s 601us/step - loss: 0.0018 - acc: 0.9981 - val_loss: 0.0301 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "# train the model - no recon\n",
    "# compile the model\n",
    "capsmodel.compile(optimizer=opt, #'adam',\n",
    "              loss=margin_loss,\n",
    "              metrics={'out_caps': 'accuracy'})\n",
    "\n",
    "data = capsmodel.fit( trainX, \n",
    "                      trainY_cat, \n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs, \n",
    "                      validation_data=[devX, devY_cat], \n",
    "                      callbacks=[log, tb, checkpoint], \n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_history( history):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8HNWZ7//Po9YueZVk493yYMBmNRZeQiZsIbEhYU1YzZL7myEzmcwk8wuZhJnJxtzc8Ls3kx83k0wyJNcTbFYDgZDEhC0QkkE2yMbsYBuwLNnGlndr3577R5XstiypW7ZKpeX7fr36peqqU9VPl9319Dmn+hxzd0RERHqSEXcAIiIy8ClZiIhISkoWIiKSkpKFiIikpGQhIiIpKVmIiEhKShYigJn9wsz+e5plN5nZx6OOSWQgUbIQEZGUlCxEhhAzy4w7BhmalCxk0Aibf75qZq+ZWZ2Z/R8zG29mT5jZATN7xszGJJW/xMzeNLO9Zva8mc1K2jbHzNaG+z0I5HZ6rU+Z2bpw3xfN7LQ0Y7zYzF4xs/1mVmVm3+60/aPh8faG228O1+eZ2b+aWaWZ7TOzP4XrzjWz6i7Ow8fD5W+b2cNmdo+Z7QduNrN5ZlYevsY2M/uRmWUn7X+ymT1tZrvNbLuZ/aOZHWdm9WZWlFRurpnVmFlWOu9dhjYlCxlsrgQuBE4APg08AfwjUEzw//nvAMzsBOB+4MtACbAS+LWZZYcXzseA5cBY4KHwuIT7ngksBT4PFAH/ATxuZjlpxFcH3AiMBi4G/trMLguPOzWM99/CmM4A1oX7fR+YC3wkjOkfgPY0z8mlwMPha94LtAF/H56ThcAFwBfCGEYAzwC/AyYCxwPPuvuHwPPAVUnHXQI84O4tacYhQ5iShQw2/+bu2919C/BHYLW7v+LuTcCjwJyw3NXAb9396fBi930gj+BivADIAu509xZ3fxh4Oek1/hL4D3df7e5t7n430BTu1yN3f97dX3f3dnd/jSBhnRNuvh54xt3vD193l7uvM7MM4L8BX3L3LeFrvhi+p3SUu/tj4Ws2uPsad1/l7q3uvokg2XXE8CngQ3f/V3dvdPcD7r463HY3QYLAzBLAtQQJVUTJQgad7UnLDV08LwyXJwKVHRvcvR2oAiaF27b44aNoViYtTwO+Ejbj7DWzvcCUcL8emdl8M3subL7ZB/wVwTd8wmO818VuxQTNYF1tS0dVpxhOMLPfmNmHYdPU/0gjBoBfAbPNbAZB7W2fu790lDHJEKNkIUPVVoKLPgBmZgQXyi3ANmBSuK7D1KTlKuC77j466ZHv7ven8br3AY8DU9x9FPBToON1qoA/62KfnUBjN9vqgPyk95EgaMJK1nno6J8A7wAz3X0kQTNdqhhw90ZgBUEN6AZUq5AkShYyVK0ALjazC8IO2q8QNCW9CJQDrcDfmVmmmV0BzEva92fAX4W1BDOzgrDjekQarzsC2O3ujWY2D7guadu9wMfN7KrwdYvM7Iyw1rMU+IGZTTSzhJktDPtI1gO54etnAf8MpOo7GQHsB2rN7CTgr5O2/QY4zsy+bGY5ZjbCzOYnbV8G3AxcAtyTxvuVYULJQoYkd3+XoP393wi+uX8a+LS7N7t7M3AFwUVxD0H/xi+T9q0g6Lf4Ubh9Y1g2HV8AbjezA8A3CZJWx3E3AxcRJK7dBJ3bp4ebbwVeJ+g72Q38f0CGu+8Lj/lzglpRHXDY3VFduJUgSR0gSHwPJsVwgKCJ6dPAh8AG4Lyk7f9F0LG+NuzvEAHANPmRiCQzs98D97n7z+OORQYOJQsROcjMzgKeJuhzORB3PDJwqBlKRAAws7sJfoPxZSUK6Uw1CxERSUk1CxERSWnIDDpWXFzs06dPjzsMEZFBZc2aNTvdvfNvd44wZJLF9OnTqaioiDsMEZFBxcwqU5dSM5SIiKRByUJERFKKLFmY2VIz22Fmb3Sz3czsh2a20YL5Cc5M2naTmW0IHzdFFaOIiKQnyj6LXxAMl7Csm+2LgZnhYz7B4GfzzWws8C2gjGCAtDVm9ri77+ltAC0tLVRXV9PY2HgU4Q8uubm5TJ48mawszVMjIn0vsmTh7i+Y2fQeilwKLAuHiV5lZqPNbAJwLvC0u+8GMLOngUUE8wL0SnV1NSNGjGD69OkcPsDo0OLu7Nq1i+rqakpLS+MOR0SGoDj7LCZx+Dj81eG67tYfwcxuMbMKM6uoqak5YntjYyNFRUVDOlEAmBlFRUXDogYlIvGIM1l0dQX3HtYfudL9Lncvc/eykpKubxMe6omiw3B5nyISjzh/Z1FNMBlNh8kEE9ZUEzRFJa9/vt+iEhHpA+5Oa7vT2ua0tLfT2ua0trXT0h78Pbjt4HI7LW1Oa1i2Y31LWzttnY7TeZ/xI3O5bv7U1EEdgziTxePAF83sAYIO7n3uvs3MngT+h5mNCct9ArgtriCP1d69e7nvvvv4whe+0Kv9LrroIu677z5Gjx4dUWQiA4+709TaTlNr+8ELasfFsrsLaWu4vqXNw3KHrzt0nMMv1snHPLxcp/07LvRdXdAPxhOsa0tODO39N+7enKmjB2+yMLP7CWoIxWZWTXCHUxaAu/8UWEkwEcxGoB74XLhtt5n9C8EkMAC3d3R2D0Z79+7l3//9349IFm1tbSQSiW73W7lyZdShiRy11rZ26lvaqG9qo765lfrmtvDRSkPScn2n5YbmNuoOW26joVO5/rjGJjKMzAwjK5FBZsLIzMggK2FkJoysjMPXJTKMzEQGuVkZZOZkBuXCMlmJDDLD7cHfw9dldfxN2KF1CSPR8XoHj3PkMQ/F1vXrHdwnw8jIiL4ZOsq7oa5Nsd2Bv+lm21KCaSYHva9//eu89957nHHGGWRlZVFYWMiECRNYt24db731FpdddhlVVVU0NjbypS99iVtuuQU4NHxJbW0tixcv5qMf/SgvvvgikyZN4le/+hV5eXkxvzMZ6NydhpbwItzURn1L66Hl5lYaWtqoa0q6wLe0Ud8UlklaDsoll2mjua29V7HkZSXIz06Qlx38zc/OJD87wej8rIPLedkJCrIzyctOkJOZQVYig0RGqgtpx0X+0MU6eV3HxfrwJGDq4zsKQ2ZsqFS+8+s3eWvr/j495uyJI/nWp0/uscwdd9zBG2+8wbp163j++ee5+OKLeeONNw7e4rp06VLGjh1LQ0MDZ511FldeeSVFRUWHHWPDhg3cf//9/OxnP+Oqq67ikUceYcmSJX36XiQe7k5zW3uP38aDC3wr9S3ht/GmNhrCC3/ycse39kPHautVLFkJ6/LCPbYgmylj8g9e6Du2dS6XnASSl/OyEv3yzVeiNWySxUAxb968w34L8cMf/pBHH30UgKqqKjZs2HBEsigtLeWMM84AYO7cuWzatKnf4pXeO9DYwqad9by/s5YPdtaxaWcdu+tbjmhu6bjA96Zt24wuL86FOZmUFOZQkBNuy0qQn9PFhbvThT55W1ZCo/9I94ZNskhVA+gvBQUFB5eff/55nnnmGcrLy8nPz+fcc8/t8rcSOTk5B5cTiQQNDQ39Eqt0r6m1jc276vlgZ93Bx/vh35oDTQfLmcHEUXkUj8ghPyvBcSOzgot4Vnjhzgku1h3NNB3bDi6H38wLwuWczAw1oUgshk2yiMuIESM4cKDrGSr37dvHmDFjyM/P55133mHVqlX9HJ30pK3d2bq3oYuEUMuWPQ2HdcQWF2ZTWlzAeSeWUFpcSGlxATNKCpg6Np/crO5vZBAZLJQsIlZUVMTZZ5/NKaecQl5eHuPHjz+4bdGiRfz0pz/ltNNO48QTT2TBggUxRjo8uTs7a5vDZFAbJIOaOjbtqmPTrnqaWw915BbmZFJaXMCcKWO4Ys5kSosLKC0uYHpxAaPyNCaXDG1DZg7usrIy7zz50dtvv82sWbNiiqj/Dbf32xud+xEOPmrqONDUerBcVsKYVhQkgRlhMigtLqC0pICSwhw1AcmQY2Zr3L0sVTnVLGTI6OhHeD8pEXQ0He2sPbwfYdLoPEqLC7jizElhMihkRnEBE0fnkdCdOyJHULKQQaWjHyFoLgprCbvqu+lHyGFGcQEXnDSO6WENQf0IIkdHyUIGnO76ET7YWUflrvrDfhDWuR9hRsmhfoSRuepHEOkrShYSm/2NLWzquMuopu6wvoTapH6E7EQG04ryKS0u4PxZ48K+hEKmF+erH0GknyhZSKQaW9rYvLs+KRnUhh3NR/YjTB6TR2lxIWdOHa1+BJEBRslCjllbu7NlTwMf7DrUj9DRybxlbwPeTT9Cacmhu46mqB9BZEBTsojY0Q5RDnDnnXdyyy23kJ+fH0FkR+9PG3byxw01BxPC5i76EWaUFDB32hg+M/fw3yOoH0FkcFKyiFh3Q5Sn484772TJkiUDKlls2lnHDUtXk5UR9CPMKC7ggqR+hNLiAooLs9WPIDLEKFlELHmI8gsvvJBx48axYsUKmpqauPzyy/nOd75DXV0dV111FdXV1bS1tfGNb3yD7du3s3XrVs477zyKi4t57rnn4n4rANyzqpKEGS/8w3kcNyo37nBEpJ8Mn2TxxNfhw9f79pjHnQqL7+ixSPIQ5U899RQPP/wwL730Eu7OJZdcwgsvvEBNTQ0TJ07kt7/9LRCMGTVq1Ch+8IMf8Nxzz1FcXNy3cR+lhuY2VlRU8cmTj1OiEBlmNCZxP3rqqad46qmnmDNnDmeeeSbvvPMOGzZs4NRTT+WZZ57ha1/7Gn/84x8ZNWpU3KF26fFXt7C/sZUbFk6LOxQR6WfDp2aRogbQH9yd2267jc9//vNHbFuzZg0rV67ktttu4xOf+ATf/OY3Y4iwe+7O3S9WcsL4QuaXjo07HBHpZ6pZRCx5iPJPfvKTLF26lNraWgC2bNnCjh072Lp1K/n5+SxZsoRbb72VtWvXHrFv3NZu3sNb2/Zz48Lp6rwWGYaGT80iJslDlC9evJjrrruOhQsXAlBYWMg999zDxo0b+epXv0pGRgZZWVn85Cc/AeCWW25h8eLFTJgwIfYO7mXllYzIyeTyOZNijUNE4qEhyoeQqN5vzYEmPnLHs1w/fxrfvmRgzDgoIn0j3SHK1QwlKT348mZa2pwlC9SxLTJcKVlIj1rb2rl39WY+enwxx48rjDscEYnJkE8WQ6WZLZWo3uczb29n275G3S4rMswN6WSRm5vLrl27hnzCcHd27dpFbm7f/1BuWXklE0flcsFJ4/r82CIyeER6N5SZLQL+N5AAfu7ud3TaPg1YCpQAu4El7l4dbvufwMUECe1p4Evey6v+5MmTqa6upqam5pjfy0CXm5vL5MmT+/SYG7Yf4MX3dvHVT55IZmJIf68QkRQiSxZmlgB+DFwIVAMvm9nj7v5WUrHvA8vc/W4zOx/4HnCDmX0EOBs4LSz3J+Ac4PnexJCVlUVpaemxvZFhbPmqSrITGVxz1pS4QxGRmEX5dXEesNHd33f3ZuAB4NJOZWYDz4bLzyVtdyAXyAZygCxge4SxSie1Ta38cu0WLj5tAkWFOXGHIyIxizJZTAKqkp5Xh+uSvQpcGS5fDowwsyJ3LydIHtvCx5Pu/nbnFzCzW8yswswqhkNTU396dG01tU0aB0pEAlEmi67GhOjc53ArcI6ZvULQzLQFaDWz44FZwGSCBHO+mX3siIO53+XuZe5eVlJS0rfRD2Puzt3llZw6aRRzpoyOOxwRGQCiTBbVQHJj92Rga3IBd9/q7le4+xzgn8J1+whqGavcvdbda4EngAURxipJyt/fxcYdtdywcJrGgRIRINpk8TIw08xKzSwbuAZ4PLmAmRWbWUcMtxHcGQWwmaDGkWlmWQS1jiOaoSQay8srGZ2fxSWnT4w7FBEZICJLFu7eCnwReJLgQr/C3d80s9vN7JKw2LnAu2a2HhgPfDdc/zDwHvA6Qb/Gq+7+66hilUO27Wvgqbe2c1XZFHKzEnGHIyIDRKS/s3D3lcDKTuu+mbT8MEFi6LxfG3DkpA8SuftWb6bdnSXz1bEtIofol1ZyUHNrO/e/VMV5J45jalF+3OGIyACiZCEHPfHGNnbWNul2WRE5gpKFHLSsvJJpRfmcM1O3IYvI4ZQsBIA3t+5jTeUeblgwjYwM3S4rIodTshAguF02NyuDz87VOFAiciQlC2FffQuPrdvCpadPYlR+VtzhiMgApGQhPLSmisaWdnVsi0i3lCyGufZ2Z/mqSuZOG8Mpk0bFHY6IDFBKFsPcCxtqqNxVz42qVYhID5Qshrnl5ZUUF+aw+JQJcYciIgOYksUwVrW7nt+/u4Nr500hO1P/FUSke5GODSUD2z2rKskw47r5U9PfqW4n7NoI7pBTCNmFkDMi+JuZAxrSXGRIUrIYphpb2niwoooLZ41nwqi8wze2t8HezbBzA+x8F3auh5r1wd+G3d0fNCMTsgsge0RSIklOKAVJ6zqXCbcnb8vUdK4iA4WSxTD1+Ktbaaiv469OyoM3HjmUDHauD2oOrY2HCucXQfGJMOvTUHIiFB0fJIbmWmiqDf4mLzfVQvOBQ89rdxy+rr0lvSAzsjollp6STVfJqdO2zOxoTqbIMKBkMRzU74aadw8mA9+5no+99ypv5+4g47cdM90ajJ4aJIMZ50LxCYceBUV9G09r06Hk0Vx3ZHI5YlstNB049PfAtsOTVHtreq+byD7KZNNVbWkEJAbwx6e9PUjKbS3h39ak561J65t72Nb5eWuax+yhXLrHzsqHgmIoKAke+cWHPy8oCZ8XB/8+ErkB/L9deqW9HfZVHaod1Lx7qBmpftehcokcGkeW8nJLKVNPuJzT58wLEkLR8ZCV1/3x+1JmTvDoiyTkHiSfwxJKbZBoukpAB7eF5Rv3wr7qw8t4e5rvIzdMMgVH1mQ614gsI42L6jFeiJPLpfsejpUlIJEV1AITmeHfrKDmeXB91uHLmTmp92mpD/rH6mpg13vBcktd1zGkTCzFh/7mF6uGeZSULAablkbY/d7hyWDneti5EVobDpXLGxM0HZ10cVhDOBGKZ8LoqfzTQ6/z5K4PWfXZCyB3kA/vYQZZucGjoPjYj+ceNMH1qraTVMup3x309ySv63zhtozwApndwwU2eX0WZOenV66nC3ZGZviax3qM8HlGJmT04110zfVQHyaQum7+7t8KH74eLLc1d32c3FFJiaWo69pKx/O8MZChGSNByWLgqt/ddQfz3srDLz6jpwbJYPrHgmRQcmLYdNT1hXNnbRO/eW0b18ybwojBniiiYBbUsLLygD4Yqt09+JbsnnSR1W3KRyU7H7KnBv/nU3GHpv1JyaQjoSQ/r4Hd70PV6qD23VVtzDKChNJTM1jy85yRQ/aOQCWLOLW3w/4tQUJI7mDeuT74j9whkRM0E004HU676lBfQtHxwQeoFx58uYrmtnZuWKBfbPcLM7Wpx8EsqEHkjoKiP0tdvr0NGvZ0U2sJH/W74MPXguXGfV0fJ5HdTTNYF81i+cW9/vzGScmiP7Q2Bd9gjmg62hB86+yQOzqoGZywKEgGJR1NR9P6pCrc1u7ct3ozC2cUMXP8iGM+nsiQkZE4dFFPR2tz2CTWRWJJXr9rQ9jfUt/1cbIK0k8sBcVB7TQmShZ9qWFv101HezaBtx0qN2pqkATmnh38LU5qOoqwCvvs29vZsreBb3xqVmSvITIsZGbDyInBIx3NdV03g9XvOrS8vxq2rQvKdHd7ee7opESS1N9SNBNO+2zfvb8uKFn0lnvYdLT+yKaj2u2HyiWyg2ai406BU64MawodTUfxNEssK69kwqhcPj5rfCyvLzJsZRcEjzFpNP+6B81c3dVWOmoyOzdCZXmQcKbMV7KITWtz0HS0c31YU9hwqBkp+Ra+3FFBzeD4C4Nk0NGfMHragLoP/72aWv60cSdfufAEMhPqYBUZsMwgb3TwKD4+dfn2tqDmErGBczWLS2tz0GnV+bcJuz84vOlo5OQgGZx5w6GEUHJiUAUcBHc/LC+vJCthXDOvF+NAicjAl5GA3JGRv4ySRcNu+PkFwXJGVnDnxLjZMPuyQx3MRTODH1cNUnVNrTyyppqLTp1AyQiNtyQivRdpsjCzRcD/BhLAz939jk7bpwFLCW5o3w0scffqcNtU4OfAFMCBi9x9U58HWTgern0gSAhjpg+opqO+8ugrWzjQ1KoJjkTkqEXWeG1mCeDHwGJgNnCtmc3uVOz7wDJ3Pw24Hfhe0rZlwP9y91nAPGBHRIHCiYuDtsEhmCjcneXllcyeMJIzp46JOxwRGaSi7OmcB2x09/fdvRl4ALi0U5nZwLPh8nMd28OkkunuTwO4e627d3OjsvTkpQ928+72A9y4cBo2CPpWRGRgijJZTAKqkp5Xh+uSvQpcGS5fDowwsyLgBGCvmf3SzF4xs/8V1lQOY2a3mFmFmVXU1NR03iwEt8uOzM3k0jM6n3oRkfRFmSy6+hrrnZ7fCpxjZq8A5wBbgFaCvpQ/D7efBcwAbj7iYO53uXuZu5eVlPTBOD5DzPb9jTz55odcVTaFvGwNhiYiRy/KZFFN0DndYTKwNbmAu2919yvcfQ7wT+G6feG+r4RNWK3AY8CZEcY6JN23ejOt7c4SjQMlIscoymTxMjDTzErNLBu4Bng8uYCZFZtZRwy3EdwZ1bHvGDPrqC6cD7wVYaxDTnNrO/e9tJlzTyxherEGshORYxNZsghrBF8EngTeBla4+5tmdruZXRIWOxd418zWA+OB74b7thE0QT1rZq8TNGn9LKpYh6In3/yQmgNNul1WRPpEpPeKuvtKYGWndd9MWn4YeLibfZ8GTosyvqFseXklU8bmcc4J4+IORUSGAA0SNAS98+F+Xtq0myXzp5HI0O2yInLslCyGoGXlleRkZnBV2ZTUhUVE0qBkMcTsa2jh0bVbuOT0iYwp0MT0ItI3lCyGmEfWVNPQ0saNC6fHHYqIDCFKFkNIe7tzz6pK5kwdzamTR8UdjogMIUoWQ8ifNu7k/Z11ul1WRPqcksUQsqy8kqKCbC46dULcoYjIEKNkMURU76nn9+9s5+qzppCTqXGgRKRvpZUszOwRM7s4aWgOGWDuXb0ZgOs1DpSIRCDdi/9PgOuADWZ2h5mdFGFM0kuNLW088NJmPj5rPJNG58UdjogMQWklC3d/xt2vJxj5dRPwtJm9aGafM7OsKAOU1H772jb21LfodlkRiUzazUrhpEQ3A38BvEIwt/aZwNORRCZpW7aqkhklBZx9fFHcoYjIEJVun8UvgT8C+cCn3f0Sd3/Q3f8WKIwyQOnZq1V7ebVqLzcu0LSpIhKddEed/ZG7/76rDe5e1ofxSC8tK68kPzvBFXMnxx2KiAxh6TZDzTKz0R1PzGyMmX0hopgkTbvrmvn1a1u5fM4kRuaq60hEopNusvhLd9/b8cTd9wB/GU1Ikq4VFVU0t7arY1tEIpdussiwpAZxM0sAGtI0Rm3tzvLySuaXjuXE40bEHY6IDHHpJosngRVmdoGZnQ/cD/wuurAklefe2cGWvQ2qVYhIv0i3g/trwOeBvyaYD/sp4OdRBSWpLVtVyfiROXzi5PFxhyIiw0BaycLd2wl+xf2TaMORdHyws44X1tfw9x8/gayERmARkeillSzMbCbwPWA2kNux3t1nRBSX9GB5eSWZGca18zRtqoj0j3S/lv4nQa2iFTgPWAYsjyoo6V59cysPrali0SnHMW5kbuodRET6QLrJIs/dnwXM3Svd/dvA+dGFJd351bqtHGhsVce2iPSrdDu4G8PhyTeY2ReBLcC46MKSrrg7y8orOem4EZw1fUzc4YjIMJJuzeLLBONC/R0wF1gC3BRVUNK1iso9vL1tPzcunK5xoESkX6VMFuEP8K5y91p3r3b3z7n7le6+Ko19F5nZu2a20cy+3sX2aWb2rJm9ZmbPm9nkTttHmtkWM/tRr97VELWsvJIRuZlcNmdi3KGIyDCTMlm4exsw13r5VTZMMj8GFhPcRXWtmc3uVOz7wDJ3Pw24neCOq2T/AvyhN687VO040Mjv3tjGZ+dOIT873dZDEZG+ke5V5xXgV2b2EFDXsdLdf9nDPvOAje7+PoCZPQBcCryVVGY28Pfh8nPAYx0bzGwuMJ7gl+LDfmTbB16qoqXNuWGhpk0Vkf6Xbp/FWGAXwR1Qnw4fn0qxzySgKul5dbgu2avAleHy5cAIMysKO9P/FfhqTy9gZreYWYWZVdTU1KT1RgajlrZ27l1dyZ/PLKa0uCDucERkGEr3F9yfO4pjd9Vs5Z2e3wr8yMxuBl4guMuqFfgCsNLdq3pq/XL3u4C7AMrKyjofe8h4+q3tbN/fxH+/7NS4QxGRYSrdX3D/J0de6HH3/9bDbtVA8k+MJwNbO+2/FbgifI1C4Ep332dmC4E/D+fMKASyzazW3Y/oJB8OlpVvYtLoPM4/SXcri0g80u2z+E3Sci5Bk9HWbsp2eBmYaWalBDWGa4DrkguYWTGwOxx76jZgKYC7X59U5magbLgminc/PMCq93fztUUnkcjQ7bIiEo90m6EeSX5uZvcDz6TYpzX8Ad+TQAJY6u5vmtntQIW7Pw6cC3zPzJygGepvev8WhrblqzaRnZnB1WdpHCgRic/R3oM5E5iaqpC7rwRWdlr3zaTlh4GHUxzjF8AvjibIwe5AYwuPrt3Cp06bwNgCzTUlIvFJt8/iAIf3WXxIMMeFROiXa7dQ19zGTRoHSkRilm4zlObt7GfBOFCbOH3yKE6fMjrucERkmEvrdxZmdrmZjUp6PtrMLosuLHnxvV28V1PHDapViMgAkO6P8r7l7vs6nrj7XuBb0YQkENwuOyY/i0+dNiHuUERE0k4WXZXTAEUR2bK3gaff2s7VZ00lNysRdzgiImkniwoz+4GZ/ZmZzTCz/x9YE2Vgw9l9qytx4Pr5KW84ExHpF+kmi78FmoEHgRVAA/pNRCSaWtt44KUqLjhpHFPG5scdjogIkP7dUHXAsPwFdX974vUP2VXXrGlTRWRASfduqKfNbHTS8zFm9mR0YQ1fd5dvorS4gI8eXxx3KCIiB6XbDFUc3gEFgLvvQXNw97k3tuzjlc17WbJgGhkaB0pEBpB0k0W7mR3sbTUDpEWCAAARPElEQVSz6XQxCq0cm2Xlm8jLSvCZuZNTlhUR6U/p3v76T8CfzKxjitOPAbdEE9LwtLe+mV+t28oVZ05mVF5W3OGIiBwm3Q7u35lZGUGCWAf8iuCOKOkjKyqqaGpt50ZNmyoiA1C6Awn+BfAlggmM1gELgHKCaVblGLW3O/es2sxZ08cwa8LIuMMRETlCun0WXwLOAird/TxgDjB0J73uZ39YX8Pm3fW6XVZEBqx0k0WjuzcCmFmOu78DnBhdWMPLsvJNlIzI4ZMnHxd3KCIiXUq3g7s6/J3FY8DTZraH1NOqShoqd9Xx/Poa/vb8mWRnppu7RUT6V7od3JeHi982s+eAUcDvIotqGLlnVSUZZlw3T+NAicjA1euRY939D6lLSToamttYUVHNopOP47hRuXGHIyLSLbV7xOjxV7ewr6GFG3S7rIgMcEoWMQmmTa3khPGFzC8dG3c4IiI9UrKIydrNe3lz635uXDgdM40DJSIDm5JFTJaXb2JETiaXz5kUdygiIikpWcSg5kATv319G1fOnUxBjmanFZGBT8kiBg++vJmWNmfJAnVsi8jgEGmyMLNFZvaumW00syNm2jOzaWb2rJm9ZmbPm9nkcP0ZZlZuZm+G266OMs7+1NrWzr2rN/PR44s5flxh3OGIiKQlsmRhZgngx8BiYDZwrZnN7lTs+8Aydz8NuB34Xri+HrjR3U8GFgF3Js/UN5g98/YOtu1r1O2yIjKoRFmzmAdsdPf33b0ZeAC4tFOZ2cCz4fJzHdvdfb27bwiXtwI7gJIIY+03y8o3MXFULhecpIkGRWTwiDJZTAKqkp5Xh+uSvQpcGS5fDowws6LkAmY2D8gG3osozn6zcccBXnxvF9cvmEZmQt1FIjJ4RHnF6urHA52nYr0VOMfMXgHOAbYArQcPYDYBWA58zt3bj3gBs1vMrMLMKmpqBv6I6cvLK8lOZHD1WVPiDkVEpFeiTBbVQPJVcTKdRqp1963ufoW7zyGYuhV33wdgZiOB3wL/7O6runoBd7/L3cvcvaykZGC3UtU2tfLI2i1cfNoEigtz4g5HRKRXokwWLwMzzazUzLKBa4DHkwuYWbGZdcRwG7A0XJ8NPErQ+f1QhDH2m0fXVlPb1KqObREZlCJLFu7eCnwReBJ4G1jh7m+a2e1mdklY7FzgXTNbD4wHvhuuvwr4GHCzma0LH2dEFWvUOsaBOnXSKOZMGRI3dYnIMBPpz4fdfSWwstO6byYtPww83MV+9wD3RBlbf1r1/m427Kjlf37mNI0DJSKDkm7J6QfLyjcxOj+LS06fGHcoIiJHRckiYtv2NfDUW9u5qmwKuVmJuMMRETkqShYRu3/1ZtrdWTJfHdsiMngpWUSoubWd+16q4rwTxzG1KD/ucEREjpqSRYSeeGMbO2ubdLusiAx6ShYRWl5eybSifM6ZObB/MCgikoqSRUTe2rqfiso93LBgGhkZul1WRAY3JYuILF+1idysDD47V+NAicjgp2QRgX31LTz6yhYuPX0So/Kz4g5HROSYKVlE4KE1VTS2tKtjW0SGDCWLPtbe7tyzqpK508ZwyqRRcYcjItInlCz62Asbati0q54bVasQkSFEyaKPLS+vpLgwm0WnHBd3KCIifUbJog9V7a7n9+/u4Np5U8nJ1DhQIjJ0KFn0oXtWV5JhxnXzp8YdiohIn1Ky6CONLW08+HIVF84az4RReXGHIyLSp5Qs+sivX93K3voWbvyIOrZFZOhRsugjy1dVMnNcIQtnFMUdiohIn1Oy6APrqvbyWvU+blg4TdOmisiQpGTRB5a9uImC7ASXz5kUdygiIpFQsjhGu2qb+M1r27hy7mRG5GocKBEZmpQsjtGDFVU0t7VzwwJ1bIvI0KVkcQza2p17V21m4YwiZo4fEXc4IiKRUbI4Bs++vZ0texs0DpSIDHlKFsdg+apKJozK5cLZ4+MORUQkUkoWR+m9mlr+uGEn182bSmZCp1FEhrZIr3JmtsjM3jWzjWb29S62TzOzZ83sNTN73swmJ227ycw2hI+boozzaCwvryQrYVwzT+NAicjQF1myMLME8GNgMTAbuNbMZncq9n1gmbufBtwOfC/cdyzwLWA+MA/4lpmNiSrW3qprauWRNdVcdOoESkbkxB2OiEjkoqxZzAM2uvv77t4MPABc2qnMbODZcPm5pO2fBJ52993uvgd4GlgUYay98ti6LRxoalXHtogMG1Emi0lAVdLz6nBdsleBK8Ply4ERZlaU5r6Y2S1mVmFmFTU1NX0WeE/cneXllcyeMJIzpw6Yyo6ISKSiTBZdDZLknZ7fCpxjZq8A5wBbgNY098Xd73L3MncvKykpOdZ40/LSB7t558MD3KhxoERkGMmM8NjVwJSk55OBrckF3H0rcAWAmRUCV7r7PjOrBs7ttO/zEcaatmWrKhmZm8mlZ2gcKBEZPqKsWbwMzDSzUjPLBq4BHk8uYGbFZtYRw23A0nD5SeATZjYm7Nj+RLguVtv3N/LkGx9yVdkU8rI1baqIDB+RJQt3bwW+SHCRfxtY4e5vmtntZnZJWOxc4F0zWw+MB74b7rsb+BeChPMycHu4Llb3rd5Ma7uzRONAicgwY+5HdAUMSmVlZV5RURHZ8Vva2jn7jt8ze+JIfvG5eZG9johIfzKzNe5elqqcfnqcpiff/JAdB5p0u6yIDEtKFmlaVl7JlLF5nHPCuLhDERHpd0oWaXjnw/289MFulsyfRiJDt8uKyPCjZJGGZeWV5GRmcFXZlNSFRUSGICWLFPY3tvDYK1u45PSJjCnIjjscEZFYKFmk8Miaauqb27hx4fS4QxERiY2SRQ/a24NxoM6YMppTJ4+KOxwRkdgoWfTgv97byfs767jpI7pdVkSGNyWLHiwrr6SoIJuLTp0QdygiIrFSsuhG9Z56nn17O1efNYWcTI0DJSLDm5JFN+5dvRmA6zUOlIiIkkVXGlvaePDlKj4+azyTRufFHY6ISOyULLqw8vVt7K5r1u2yIiIhJYsu3F1eyYySAs4+vijuUEREBgQli05eq97Lq1V7uXGBpk0VEemgZNHJsvJK8rMTXDF3ctyhiIgMGEoWSfbUNfP4q1u5fM4kRuZmxR2OiMiAoWSR5MGKKppb29WxLSLSiZJFqK3duWdVJfNLx3LicSPiDkdEZEBRsgg9/+4Oqvc0qFYhItIFJYvQsvJKxo/M4RMnj487FBGRAUfJAvhgZx1/WF/DdfOmkZXQKRER6UxXRuCeVZVkZhjXztO0qSIiXRn2yaK+uZWHKqpYdMpxjBuZG3c4IiID0rBPFgcaW/nYCSXc9JHpcYciIjJgRZoszGyRmb1rZhvN7OtdbJ9qZs+Z2Stm9pqZXRSuzzKzu83sdTN728xuiyrG8SNz+dF1Z3LW9LFRvYSIyKAXWbIwswTwY2AxMBu41sxmdyr2z8AKd58DXAP8e7j+s0COu58KzAU+b2bTo4pVRER6FmXNYh6w0d3fd/dm4AHg0k5lHBgZLo8CtiatLzCzTCAPaAb2RxiriIj0IMpkMQmoSnpeHa5L9m1giZlVAyuBvw3XPwzUAduAzcD33X135xcws1vMrMLMKmpqavo4fBER6RBlsuhqfG/v9Pxa4BfuPhm4CFhuZhkEtZI2YCJQCnzFzGYccTD3u9y9zN3LSkpK+jZ6ERE5KMpkUQ0k/3BhMoeamTr8P8AKAHcvB3KBYuA64Hfu3uLuO4D/AsoijFVERHoQZbJ4GZhpZqVmlk3Qgf14pzKbgQsAzGwWQbKoCdefb4ECYAHwToSxiohIDyJLFu7eCnwReBJ4m+CupzfN7HYzuyQs9hXgL83sVeB+4GZ3d4K7qAqBNwiSzn+6+2tRxSoiIj2z4No8+JWVlXlFRUXcYYiIDCpmtsbdUzbzD5lkYWY1QOUxHKIY2NlH4fQlxdU7iqt3FFfvDMW4prl7yjuEhkyyOFZmVpFOdu1viqt3FFfvKK7eGc5xDfuxoUREJDUlCxERSUnJ4pC74g6gG4qrdxRX7yiu3hm2canPQkREUlLNQkREUlKyEBGRlIZVskhjMqYcM3sw3L66v+bQSCOum82sxszWhY+/6Ke4lprZDjN7o5vtZmY/DON+zczOHCBxnWtm+5LO1zf7Ka4p4WReb5vZm2b2pS7K9Ps5SzOufj9nZpZrZi+Z2athXN/poky/fybTjCuWz2T42olwwrjfdLEtuvPl7sPiASSA94AZQDbwKjC7U5kvAD8Nl68BHhwgcd0M/CiGc/Yx4EzgjW62XwQ8QTDC8AJg9QCJ61zgNzGcrwnAmeHyCGB9F/+W/X7O0oyr389ZeA4Kw+UsYDWwoFOZOD6T6cQVy2cyfO3/F7ivq3+vKM/XcKpZpDMZ06XA3eHyw8AFZtbVUOv9HVcs3P0F4Ih5RJJcCizzwCpgtJlNGABxxcLdt7n72nD5AMGYaJ3ncOn3c5ZmXP0uPAe14dOs8NH5jpt+/0ymGVcszGwycDHw826KRHa+hlOySGcypoNlPBgIcR9QNADiArgybLZ42MymdLE9DunGHoeFYTPCE2Z2cn+/eFj9n0PwrTRZrOesh7gghnMWNqmsA3YAT7t7t+erHz+T6cQF8Xwm7wT+AWjvZntk52s4JYt0JmNKp0xfS+c1fw1Md/fTgGc49M0hbnGcr3SsJRjv5nTg34DH+vPFzawQeAT4srt3ng44tnOWIq5Yzpm7t7n7GQTz3cwzs1M6FYnlfKURV79/Js3sU8AOd1/TU7Eu1vXJ+RpOySKdyZgOlrFg/u9RRN/ckTIud9/l7k3h058BcyOOKV3pnNN+5+77O5oR3H0lkGVmxf3x2maWRXBBvtfdf9lFkVjOWaq44jxn4WvuBZ4HFnXaFMdnMmVcMX0mzwYuMbNNBM3V55vZPZ3KRHa+hlOySGcypseBm8LlzwC/97CnKM64OrVpX0LQ5jwQPA7cGN7hswDY5+7b4g7KzI7raKc1s3kE/8939cPrGvB/gLfd/QfdFOv3c5ZOXHGcMzMrMbPR4XIe8HGOnOSs3z+T6cQVx2fS3W9z98nuPp3gOvF7d1/SqVhk5yuzLw4yGLh7q5l1TMaUAJZ6OBkTUOHujxN8oJab2UaCbHzNAInr7yyYMKo1jOvmqOMCMLP7Ce6SKTazauBbBJ19uPtPgZUEd/dsBOqBzw2QuD4D/LWZtQINwDX9kPQh+OZ3A/B62N4N8I/A1KTY4jhn6cQVxzmbANxtZgmC5LTC3X8T92cyzbhi+Ux2pb/Ol4b7EBGRlIZTM5SIiBwlJQsREUlJyUJERFJSshARkZSULEREJCUlC5EBwIJRX48YRVRkoFCyEBGRlJQsRHrBzJaEcx2sM7P/CAecqzWzfzWztWb2rJmVhGXPMLNV4WBzj5rZmHD98Wb2TDho31oz+7Pw8IXhoHTvmNm9/TDisUjalCxE0mRms4CrgbPDQebagOuBAmCtu58J/IHgF+UAy4CvhYPNvZ60/l7gx+GgfR8BOob7mAN8GZhNML/J2ZG/KZE0DZvhPkT6wAUEA8a9HH7pzyMYwrodeDAscw/wSzMbBYx29z+E6+8GHjKzEcAkd38UwN0bAcLjveTu1eHzdcB04E/Rvy2R1JQsRNJnwN3uftthK82+0alcT2Po9NS01JS03IY+nzKAqBlKJH3PAp8xs3EAZjbWzKYRfI4+E5a5DviTu+8D9pjZn4frbwD+EM4jUW1ml4XHyDGz/H59FyJHQd9cRNLk7m+Z2T8DT5lZBtAC/A1QB5xsZmsIZia7OtzlJuCnYTJ4n0MjzN4A/Ec4WmgL8Nl+fBsiR0WjzoocIzOrdffCuOMQiZKaoUREJCXVLEREJCXVLEREJCUlCxERSUnJQkREUlKyEBGRlJQsREQkpf8LxXB/QB3yxtoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Begin: test------------------------------\n",
      "Test acc: 0.9388823086034241\n"
     ]
    }
   ],
   "source": [
    "plot_history(data)\n",
    "y_pred = capsmodel.predict(testX, batch_size=100)\n",
    "print('-'*30 + 'Begin: test' + '-'*30)\n",
    "print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(testY_cat, 1))/testY_cat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testPred = [ 3, 5, 3, 4, 7, 3, 9]\n",
    "testPred = np.array(testPred / np.linalg.norm(testPred))\n",
    "print(testPred)\n",
    "testTrue = trainY_cat[0]\n",
    "print(testTrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#margin_loss( trainY_cat[0], testPred)\n",
    "L = testTrue * np.square(np.maximum(0., 0.9 - testPred)) + 0.5 * (1 - testTrue) * np.square(np.maximum(0., testPred - 0.1))\n",
    "print(L)\n",
    "print(np.mean(np.sum(L, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"# compile the model\n",
    "capsmodel.compile(optimizer=opt, #'adam',\n",
    "              loss=[margin_loss, 'mse'],\n",
    "              loss_weights=[1., lam_recon],\n",
    "              metrics={'out_caps': 'accuracy'})\n",
    "\n",
    "# train the model\n",
    "data = capsmodel.fit( [trainX, trainY_cat], \n",
    "                      [trainY_cat, trainX], \n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs, \n",
    "                      #validation_data=[[devX], [devY_cat]], \n",
    "                      validation_data=[[devX, devY_cat], [devY_cat, devX]], \n",
    "                      callbacks=[log, tb, checkpoint], \n",
    "                      verbose=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX.shape\n",
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(devX.shape)\n",
    "print(devY.shape)\n",
    "print(devY_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
